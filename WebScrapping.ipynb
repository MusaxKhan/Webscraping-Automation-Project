{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "700abcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e876b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def extract_email_from_company_website(url):\n",
    "    try:\n",
    "        # Set a browser user-agent so the website doesn't block the request as a bot\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "        # Send an HTTP GET request to the company's website\n",
    "        res = requests.get(url, headers=headers, timeout=10)\n",
    "\n",
    "        # If the request failed (e.g., 404 or timeout), return \"N/A\"\n",
    "        if res.status_code != 200:\n",
    "            return \"N/A\"\n",
    "\n",
    "        # Parse the website content (HTML) using BeautifulSoup\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "        # Get all the text from the page (without tags) to search for emails\n",
    "        text = soup.get_text()\n",
    "\n",
    "        # Use a regular expression to find email patterns in the text\n",
    "        emails = re.findall(\n",
    "            r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", text\n",
    "        )\n",
    "\n",
    "        # Return the first email found, or \"N/A\" if no email was found\n",
    "        return emails[0] if emails else \"N/A\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # If any error occurs (network issue, bad HTML, etc.), return \"N/A\"\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return \"N/A\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216af1d8",
   "metadata": {},
   "source": [
    "# Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f054975",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'webdriver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Setup driver\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241m.\u001b[39mChrome(service\u001b[38;5;241m=\u001b[39mService(ChromeDriverManager()\u001b[38;5;241m.\u001b[39minstall()))\n\u001b[0;32m      3\u001b[0m companies_collected \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Open website\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'webdriver' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "companies_collected = 0\n",
    "# Open website\n",
    "driver.get(\"https://www.hotfrog.co.id\")\n",
    "\n",
    "# Wait and search\n",
    "search_bar = driver.find_element(By.XPATH, \"/html/body/header/div[2]/div/div[2]/form/div/div[1]/input\")\n",
    "search_bar.send_keys(\"Motorcycle Spare Parts\")\n",
    "\n",
    "search_click = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"/html/body/header/div[2]/div/div[2]/form/div/button\"))\n",
    ")\n",
    "try:\n",
    "    search_click.click()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"serps\")))\n",
    "#print(\"Entered the Motorcycle Page\")\n",
    "\n",
    "start_company = 1\n",
    "end_company = 18\n",
    "page = 1\n",
    "\n",
    "\n",
    "name = []\n",
    "email = []\n",
    "phone = []\n",
    "address = []\n",
    "while page < 115:\n",
    "    start_company = 1\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"serps\")))\n",
    "\n",
    "    companies = driver.find_elements(By.CSS_SELECTOR, \".hf-box.clearfix\")\n",
    "    print(f\"Found {len(companies)} companies on page {page}\")\n",
    "\n",
    "    for i in range(len(companies)):\n",
    "        try:\n",
    "            company_header = companies[i].find_element(By.CLASS_NAME, \"h6.mb-0\")\n",
    "            company_link = company_header.find_element(By.TAG_NAME, 'a')\n",
    "\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", company_link)\n",
    "            href = company_link.get_attribute(\"href\")\n",
    "            #the_link = href.replace(\"company\", \"message\")\n",
    "            if not href or \"javascript:void\" in href:\n",
    "                start_company+=1\n",
    "                continue\n",
    "            link = company_link.get_attribute(\"href\")\n",
    "            #print(f\"Entered {link}\")\n",
    "            # Scroll into view\n",
    "            time.sleep(1)\n",
    "\n",
    "            # Try clicking\n",
    "            try:\n",
    "                company_link.click()\n",
    "            except:\n",
    "                # Fallback to JS click\n",
    "                driver.execute_script(\"arguments[0].click();\", company_link)\n",
    "\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"bdp\")))\n",
    "\n",
    "            #print(\"Entered Company's Page\")\n",
    "\n",
    "\n",
    "            # Name\n",
    "            Name = driver.find_element(By.CSS_SELECTOR, \".lead.hfhl\").text\n",
    "            name.append(Name)\n",
    "            print(f\"Company {start_company} : {Name}, Page {page}\")\n",
    "            company_url = \"N/A\"\n",
    "            try:\n",
    "                company_url_elem = driver.find_element(By.XPATH, \"//i[contains(@class, 'fa-link')]/following-sibling::a[1]\")\n",
    "                company_url = company_url_elem.get_attribute(\"href\")\n",
    "                print(\"Company website:\", company_url)\n",
    "            except:\n",
    "                print(\"No external website found.\")\n",
    "\n",
    "            ## Here add the logic of finding comanies url\n",
    "            # Email-Phone-Address\n",
    "            contact = driver.find_element(By.ID, \"bdp-contacts\")\n",
    "            temp = contact.find_elements(By.TAG_NAME, \"dt\")\n",
    "            phone_done = True\n",
    "            email_done = True\n",
    "            address_done = True\n",
    "\n",
    "        \n",
    "            for j in range(len(temp)):\n",
    "                label = temp[j].text.strip().lower()\n",
    "                #print(label)\n",
    "\n",
    "                if label in [\"mobile\", \"telepon\", \"phone\"] and phone_done == True:\n",
    "                    try:\n",
    "                        dd = temp[j].find_element(By.XPATH, \"following-sibling::dd[1]\")\n",
    "                        phone.append(dd.text)\n",
    "                        #print(dd.text)\n",
    "                        phone_done = False\n",
    "                    except:\n",
    "                        phone.append(np.nan) \n",
    "\n",
    "                elif label in [\"alamat\", \"address\"]:\n",
    "                    try:\n",
    "                        dd = temp[j].find_element(By.XPATH, \"following-sibling::dd[1]\")\n",
    "                        \n",
    "                        address.append(dd.text)\n",
    "                        address_done = False\n",
    "                        #print(dd.text)\n",
    "                    except:\n",
    "                        address.append(np.nan)\n",
    "            # If something is missed\n",
    "            if email_done == True:\n",
    "                if company_url == \"N/A\":\n",
    "                    email.append(np.nan)\n",
    "                else:\n",
    "                    fallback_email = extract_email_from_company_website(company_url) if company_url != \"N/A\" else \"N/A\"\n",
    "                    email.append(fallback_email)\n",
    "\n",
    "            if phone_done == True:\n",
    "                phone.append(np.nan)\n",
    "            if address_done == True:\n",
    "                address.append(np.nan)\n",
    "        \n",
    "        #\n",
    "            driver.back()\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"serps\")))\n",
    "            #print(\"Left Company's Page\")\n",
    "            companies = driver.find_elements(By.CSS_SELECTOR, \".hf-box.clearfix\")\n",
    "            companies_collected+=1\n",
    "        except Exception as e:\n",
    "            print(f\"Error at company {start_company}: {e}\")\n",
    "        start_company += 1\n",
    "        \n",
    "    print(f\"Page : {page} completed\")\n",
    "    try:\n",
    "        pagination_container = driver.find_element(By.CSS_SELECTOR, \".py-3.bg-white\")\n",
    "        next_page_link = pagination_container.find_elements(By.CSS_SELECTOR, \".page-link.border-0\")\n",
    "        next_page_link = next_page_link[-1]\n",
    "        print(next_page_link.get_attribute(\"href\"))\n",
    "        print(next_page_link.text)\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_link)\n",
    "        time.sleep(1)\n",
    "        href = next_page_link.get_attribute(\"href\")\n",
    "        if href and \"javascript\" not in href:\n",
    "            driver.get(href)\n",
    "        else:\n",
    "            try:\n",
    "                next_page_link.click()\n",
    "            except:\n",
    "                driver.execute_script(\"arguments[0].click();\", next_page_link)\n",
    "        time.sleep(2)\n",
    "        page += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"No more pages or error in pagination:\", e)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b830cd",
   "metadata": {},
   "source": [
    "# Load the data collected to Panda Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3c419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Company_Name\" :name, \"Email_Address\":email, \"Phone_Number\":phone, \"Address\":address}\n",
    "dataset = pd.DataFrame(data)\n",
    "dataset.to_csv(\"Datasets\\\\Motorcycle_Spare_Parts-2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5983f2",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733bdd68",
   "metadata": {},
   "source": [
    "### Duplicate Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e66ff8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset before dropping duplicates: (1341, 5)\n",
      "Shape of the dataset after dropping duplicates: (1341, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of the dataset before dropping duplicates: {dataset.shape}\")\n",
    "dataset.drop_duplicates()\n",
    "print(f\"Shape of the dataset after dropping duplicates: {dataset.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6674bb",
   "metadata": {},
   "source": [
    "### Find Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb5509fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "Company_Name       0\n",
       "Email_Address      0\n",
       "Phone_Number     103\n",
       "Address          137\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77375cce",
   "metadata": {},
   "source": [
    "### Drop missing rows (missing rows are saved in another CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19ee4bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset after dropping Null containing rows: (1341, 5)\n",
      "Shape of the dataset after dropping Null containing rows: (1112, 5)\n"
     ]
    }
   ],
   "source": [
    "# Save it in other csv\n",
    "dataset[dataset[\"Phone_Number\"].isnull() | dataset[\"Address\"].isnull()].to_csv(\"Datasets\\\\Removed_Rows.csv\")\n",
    "\n",
    "# Drop them\n",
    "print(f\"Shape of the dataset after dropping Null containing rows: {dataset.shape}\")\n",
    "dataset = dataset.dropna(subset=[\"Phone_Number\", \"Address\"])\n",
    "print(f\"Shape of the dataset after dropping Null containing rows: {dataset.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ba1bb1",
   "metadata": {},
   "source": [
    "# Final CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb4a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"Datasets\\\\Indonesia.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
